"""Import GOLD markdown examples and insert into DB."""

import os
import re
import sys
import unicodedata
from datetime import datetime

from run_batch import check_and_repair, dedup_and_embed_titles, ensure_db, insert_bundle

# ------------------------------- ×§×•× ×¤×™×’ ×•×–×™×”×•×™ ×¡×§×©× ×™× -------------------------------

SEC_NAMES = [
    "×¡×™×¤×•×¨ ××§×¨×”",
    "×©×œ×‘×™ ×ª×’×•×‘×”",
    "× ×•×”×œ ×¤×ª×™×—×” ×‘××©",
    "×¨×§×¢ ××‘×¦×¢×™",
    "×§×™×©×•×¨",
    "×œ×™× ×§",
    "CCTV",
    "×¡××›×•×™×•×ª",
    "× ×§×•×“×•×ª ×”×›×¨×¢×”",
    "×ª× ××™ ×”×¡×œ××”",
    "×”×¦×œ×—×ª ××™×¨×•×¢",
    "×›×©×œ ××™×¨×•×¢",
    "×œ×§×—×™×",
    "×•×¨×™××¦×™×•×ª",
    # ×©×“×•×ª ××˜× ×©×™×›×•×œ×™× ×œ×”×•×¤×™×¢ ×›×¡×§×©×Ÿ ×¢× ×¢×¨×š ×‘×©×•×¨×” ×”×‘××”
    "×§×˜×’×•×¨×™×”",
    "×¨××ª ×¡×™×›×•×Ÿ",
    "×¨××ª ×¡×‘×™×¨×•×ª",
    "×¨××ª ××•×¨×›×‘×•×ª",
    "××™×§×•×",
    "×©×™××•×© ×‘××¡×›×”",
]

# ×“×¨×•×© ××—×“: ×›×•×ª×¨×ª Markdown (##+), ××•×“×’×©×ª (**×©×**), ××• ×©× ×¡×§×©×Ÿ ×¢× × ×§×•×“×ª×™×™×
_HDR_RE = re.compile(
    r"^\s*(?:#{2,}\s*(?P<h1>.+?)\s*$|\*\*\s*(?P<h2>.+?)\s*\*\*\s*$|(?P<h3>[^:]{2,60}):\s*$)",
    re.M,
)

KV_MAP = {
    "×§×˜×’×•×¨×™×”": "category",
    "×¨××ª ×¡×™×›×•×Ÿ": "threat_level",
    "×¨××ª ×¡×‘×™×¨×•×ª": "likelihood",
    "×¨××ª ××•×¨×›×‘×•×ª": "complexity",
    "× ×•×”×œ ×¤×ª×™×—×” ×‘××©": "rules_of_engagement",
    "×©×™××•×© ×‘××¡×›×”": "mask_usage",
    "××™×§×•×": "location",
}

# --- × ×™×§×•×™ ×××•×’'×™ ×•×ª×•×•×™ ×§×™×©×•×˜ ××›×•×ª×¨×•×ª ×©×“×•×ª/×¡×§×©× ×™× ---
_EMOJI_RE = re.compile(
    r"[\U0001F300-\U0001FAFF\U00002700-\U000027BF\U0001F900-\U0001F9FF\U0001FA70-\U0001FAFF\U00002600-\U000026FF\U00002B00-\U00002BFF\U0000FE0F]+",
    re.UNICODE,
)


def _normalize_hebrew(text: str) -> str:
    """Apply Unicode NFC normalization to Hebrew text.

    NFC (Canonical Decomposition, followed by Canonical Composition) ensures
    that Hebrew characters with diacritics are stored in their canonical composed form,
    preventing comparison issues with visually identical but byte-different strings.
    """
    if not text:
        return text
    return unicodedata.normalize("NFC", text)


def _clean_label(s: str) -> str:
    # ××¡×™×¨ ×××•×’'×™, ×ª×•×•×™ ×¢×™×¦×•×‘, # ×•-*, ×•××©××™×¨ ×¨×§ ×˜×§×¡×˜ × ×§×™ ×œ×”×©×•×•××” ××•×œ ×”××¤×ª×— ×”×¢×‘×¨×™
    s = _EMOJI_RE.sub("", s or "")
    s = s.replace("**", "").replace("#", "").strip()
    # × ×˜×¨×•×œ ×¨×•×•×—×™× ×›×¤×•×œ×™×
    s = re.sub(r"\s+", " ", s)
    # Apply NFC normalization for consistent Hebrew comparison
    return _normalize_hebrew(s)


def _map_k(k: str) -> str | None:
    """××§×‘×œ ×ª×•×•×™×ª ×‘×¢×‘×¨×™×ª (×œ××—×¨ × ×™×§×•×™) ×•××—×–×™×¨ ××ª ×©× ×”×©×“×” ×”×§× ×•× ×™ ×‘-JSON ×œ×¤×™ KV_MAP."""
    k = _clean_label(k)
    # × ×™×¡×™×•×Ÿ ×”×ª×××” ×™×©×™×¨×”
    if k in KV_MAP:
        return KV_MAP[k]
    # × ×™×¡×™×•×Ÿ ×”×ª×××” ×¢"×™ ×”×›×œ×” ×“×•-×›×™×•×•× ×™×ª (×œ×›×•×ª×¨×•×ª ×¢× ××™×œ×™× × ×•×¡×¤×•×ª)
    for he_key, canon in KV_MAP.items():
        if he_key in k or k in he_key:
            return canon
    return None


LINK_RE = re.compile(r"\((https?://[^\s)]+)\)|\b(https?://[^\s)]+)")

# --------------------------------- ×¢×–×¨×™ ×”××¨×” ---------------------------------


def _he_bool(v: str):
    v = (v or "").strip().lower()
    if v in {"yes", "×›×Ÿ", "true", "y"}:
        return "×›×Ÿ"
    if v in {"no", "×œ×", "false", "n"}:
        return "×œ×"
    return None if not v else v  # ×¨×™×§ => None, ××—×¨×ª ×”×—×–×¨ ×”××§×•×¨


def _is_heading_line(line: str) -> str | None:
    """
    ×× ×”×©×•×¨×” ×”×™× ×›×•×ª×¨×ª ×¡×§×©×Ÿ â€“ ×”×—×–×¨ ××ª ×©× ×”×›×•×ª×¨×ª; ××—×¨×ª None.
    ××›×¡×”: ## ×›×•×ª×¨×ª, **×›×•×ª×¨×ª**, ××• '×›×•×ª×¨×ª:'.
    """
    m = _HDR_RE.match(line)
    if not m:
        return None
    name = m.group("h1") or m.group("h2") or m.group("h3") or ""
    name = name.strip().strip("*").strip()
    # × ×‘×“×•×§ ×©×”×™× ××—×ª ××¨×©×™××ª ×”×¡×§×©× ×™× ×”××•×›×¨×™× (××• ××›×™×œ×” ××•×ª×)
    for nm in SEC_NAMES:
        if nm in name:
            return nm
    return None


def _section(md: str, wanted_name: str) -> str:
    """
    ×—×™×œ×•×¥ ×˜×§×¡×˜ ×‘×™×Ÿ ×›×•×ª×¨×ª ×”×¡×§×©×Ÿ ×”××‘×•×§×© ×œ×›×•×ª×¨×ª ×”×¡×§×©×Ÿ ×”×‘××”.
    """
    lines = md.splitlines(True)  # ×›×•×œ×œ \n
    start_idx = None
    for i, ln in enumerate(lines):
        hdr = _is_heading_line(ln)
        if hdr and wanted_name in ln:
            start_idx = i + 1
            break
    if start_idx is None:
        return ""
    end_idx = len(lines)
    for j in range(start_idx, len(lines)):
        if _is_heading_line(lines[j]):
            end_idx = j
            break
    return "".join(lines[start_idx:end_idx]).strip()


def _lines_or_sentences(txt: str) -> list[str]:
    txt = (txt or "").strip()
    if not txt:
        return []
    lines = [line.strip(" \t-â€¢") for line in txt.splitlines() if line.strip()]
    if len(lines) > 1:
        return lines
    parts = re.split(r"[.!?]\s+", txt)
    return [p.strip(" \n-â€¢") for p in parts if p.strip()]


def _first_nonempty_line(txt: str) -> str:
    for ln in (txt or "").splitlines():
        val = ln.strip()
        if val:
            return val
    return ""


def _canon_level(val: str | None) -> str | None:
    if not val:
        return None
    v = val.strip()
    mapping = globals().get("CANON_LEVELS", {}) or {}
    return mapping.get(v, v)


# --------------------------------- ×¤×¨×¡×•×¨ MD ---------------------------------


def parse_md_to_scenario(md_text: str) -> dict:
    # Normalize Unicode to NFC for consistent Hebrew text handling
    md = _normalize_hebrew(md_text.replace("\r\n", "\n"))

    # ×›×•×ª×¨×ª: "# ..." ××• "ğŸ§© ×›×•×ª×¨×ª: ..."
    title = None
    m = re.search(r"^\s*#\s*(.+)$", md, re.M)
    if m:
        title = m.group(1).strip()
    if not title:
        m = re.search(r"ğŸ§©\s*×›×•×ª×¨×ª[:ï¼š]\s*(.+)", md)
        if m:
            title = m.group(1).strip()
    if not title:
        title = "×œ×œ× ×›×•×ª×¨×ª"

    # ×‘×œ×•×§ ×›×•×ª×¨×ª-×¢×œ: ×¢×“ ×›×•×ª×¨×ª ×¡×§×©×Ÿ ×¨××©×•× ×”
    lines = md.splitlines()
    header_end = len(lines)
    for i, ln in enumerate(lines):
        if _is_heading_line(ln):
            header_end = i
            break
    header_block = "\n".join(lines[:header_end])

    # ××¤×” ×©×œ KV
    kv = {}
    for line in header_block.splitlines():
        if ":" not in line:
            continue
        k, v = line.split(":", 1)
        k = _clean_label(k)
        v = v.strip()
        key = _map_k(k)
        if not key:
            continue
        if key in {"mask_usage", "rules_of_engagement"}:
            kv[key] = _he_bool(v)
        elif key in {"threat_level", "likelihood", "complexity"}:
            kv[key] = _canon_level(v)
        else:
            kv[key] = v

    # --- Fallback: × ×¡×” ×œ×—×œ×¥ ×¢×¨×›×™× ×©××•×¤×™×¢×™× ×›×¡×§×©×Ÿ ×¢× ×¢×¨×š ×‘×©×•×¨×” ×”×‘××” ---
    for he_key, canon in KV_MAP.items():
        if kv.get(canon):
            continue
        sec_txt = _section(md, he_key)
        if not sec_txt:
            continue
        val = _first_nonempty_line(sec_txt)
        if not val:
            continue
        if canon == "rules_of_engagement":
            # ×œ×˜×§×¡×˜ ×”××œ× × ×˜×¤×œ ×‘×”××©×š ×‘-roe_text
            continue
        if canon == "mask_usage":
            kv[canon] = _he_bool(val)
        elif canon in {"threat_level", "likelihood", "complexity"}:
            kv[canon] = _canon_level(val)
        else:
            kv[canon] = val

    # ×©×œ×™×¤×•×ª ×¡×§×©× ×™×
    background = _section(md, "×¡×™×¤×•×¨ ××§×¨×”")
    steps_raw = _section(md, "×©×œ×‘×™ ×ª×’×•×‘×”")
    roe_text = _section(md, "× ×•×”×œ ×¤×ª×™×—×” ×‘××©")
    op_bg = _section(md, "×¨×§×¢ ××‘×¦×¢×™")
    media_sec = _section(md, "×§×™×©×•×¨") or _section(md, "×œ×™× ×§")
    cctv_sec = _section(md, "CCTV")
    auth_sec = _section(md, "×¡××›×•×™×•×ª")
    dp_sec = _section(md, "× ×§×•×“×•×ª ×”×›×¨×¢×”")
    esc_sec = _section(md, "×ª× ××™ ×”×¡×œ××”")
    succ_sec = _section(md, "×”×¦×œ×—×ª ××™×¨×•×¢")
    fail_sec = _section(md, "×›×©×œ ××™×¨×•×¢")
    lessons_sec = _section(md, "×œ×§×—×™×")
    vars_sec = _section(md, "×•×¨×™××¦×™×•×ª")

    steps = _lines_or_sentences(steps_raw)
    decision_points = _lines_or_sentences(dp_sec)
    escalation = _lines_or_sentences(esc_sec)
    lessons = _lines_or_sentences(lessons_sec)
    variations = _lines_or_sentences(vars_sec)

    # ×§×™×©×•×¨ ×œ××“×™×” (×ª×•××š ×’× ×‘-(http...) ×•×’× ×‘-×˜×§×¡×˜ ×—×©×•×£)
    m = LINK_RE.search(media_sec or "")
    media_link = (m.group(1) or m.group(2)) if m else None

    scenario = {
        "external_id": "",
        "title": title,
        "category": kv.get("category") or "",
        "threat_level": kv.get("threat_level"),
        "likelihood": kv.get("likelihood"),
        "complexity": kv.get("complexity"),
        "location": kv.get("location") or "",
        "background": background or "",
        "steps": steps,
        "required_response": [],
        "debrief_points": [],
        "operational_background": op_bg or "××™×Ÿ ×ª×™×¢×•×“ ×¨×œ×•×•× ×˜×™",
        "media_link": media_link,
        "mask_usage": kv.get("mask_usage"),  # "×›×Ÿ"/"×œ×"/None
        "authority_notes": auth_sec or "",
        "cctv_usage": cctv_sec or "",
        "comms": [],
        "decision_points": decision_points,
        "escalation_conditions": escalation,
        "end_state_success": succ_sec or "",
        "end_state_failure": fail_sec or "",
        "lessons_learned": lessons,
        "variations": variations,
        "validation": ["json_valid", "ethical_balance_ok"],
    }

    # ROE
    roe_text = (roe_text or "").strip()
    if roe_text:
        scenario["rules_of_engagement"] = roe_text
    elif kv.get("rules_of_engagement") in {"×›×Ÿ", "×œ×"}:
        scenario["rules_of_engagement"] = kv["rules_of_engagement"]
    else:
        scenario["rules_of_engagement"] = None

    return scenario


# --------------------------------- main ---------------------------------


def main():
    if len(sys.argv) < 2:
        print("Usage: python import_gold_md.py <folder_with_md>")
        sys.exit(1)

    folder = sys.argv[1]
    if not os.path.isdir(folder):
        print("×”×ª×™×§×™×™×” ×œ× ×§×™×™××ª:", folder)
        sys.exit(1)

    files = sorted(os.path.join(folder, f) for f in os.listdir(folder) if f.lower().endswith(".md"))
    if not files:
        print("×œ× × ××¦××• ×§×‘×¦×™ .md ×‘×ª×™×§×™×™×”:", folder)
        sys.exit(1)

    scenarios = []
    errors = 0

    for path in files:
        try:
            with open(path, encoding="utf-8") as fh:
                md = fh.read()
            sc = parse_md_to_scenario(md)
            sc["external_id"] = f"GOLD-{os.path.splitext(os.path.basename(path))[0]}"
            scenarios.append(sc)
        except Exception as e:
            errors += 1
            print(f"âš ï¸  ×©×’×™××” ×‘×¤×¨×¡×•×¨ '{os.path.basename(path)}': {e}")

    # ×¡×™× ×•×Ÿ ×ª×¡×¨×™×˜×™× ×¨×™×§×™× (×œ××©×œ ×× ××™×Ÿ ×›×•×ª×¨×ª ×•×ª×•×›×Ÿ)
    scenarios = [s for s in scenarios if s.get("title") and (s.get("background") or s.get("steps"))]

    bundle = {
        "bundle_id": f"GOLD-{datetime.now().strftime('%Y%m%d-%H%M')}",
        "scenarios": scenarios,
    }

    # ×”×›× ×¡×” ××¡×•×“×¨×ª ×œÖ¾DB â€“ ×¢× × ×¤×™×œ×•×ª ×¨×›×•×ª
    ensure_db()

    try:
        bundle = check_and_repair(bundle)
    except Exception as e:
        print(f"âš ï¸  check_and_repair × ×›×©×œ: {e} â€” ×××©×™×›×™× ×¢× ×”× ×ª×•× ×™× ×”×’×•×œ××™×™×")

    try:
        bundle = dedup_and_embed_titles(bundle)
    except Exception as e:
        print(f"âš ï¸  ×××‘×“×™× ×’/×“×“×•×¤ × ×›×©×œ: {e} â€” × ×©××¨ ×‘×œ×™ ×××‘×“×™× ×’")

    insert_bundle(bundle, owner="GoldSeed", approved_by="Gold")

    print(f"âœ” ×”×•×›× ×¡×• {len(bundle['scenarios'])} ×ª×˜×œ\"××™× ×›-Gold. bundle_id={bundle['bundle_id']}")
    if errors:
        print(f"â„¹ï¸  ×”×™×• {errors} ×§×‘×¦×™× ×¢× ×©×’×™××•×ª ×¤×¨×¡×•×¨ â€” ×¨××• ×œ×•×’ ×œ××¢×œ×”.")
    for sc in bundle["scenarios"]:
        print(" â€¢", sc.get("title", "(×œ×œ× ×›×•×ª×¨×ª)"))


if __name__ == "__main__":
    main()
