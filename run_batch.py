import argparse
import json
import logging
import os
import pathlib
import re
import sqlite3
import time
from datetime import datetime

import numpy as np
from openai import BadRequestError

from config import (
    CHECKER_MODEL,
    DB_PATH,
    EMB_TABLE,
    EMBED_MODEL,
    GEN_MODEL,
    LOCAL_MODEL,
    SIM_THRESHOLD,
    TABLE_NAME,
    VALIDATOR_MODEL,
    client_cloud,
    client_local,
)
from tatlam import configure_logging

configure_logging()

LOGGER = logging.getLogger(__name__)

DEBUG_DIR = pathlib.Path("debug")
DEBUG_DIR.mkdir(exist_ok=True)


def _dbg(name: str, obj):
    (DEBUG_DIR / f"{name}.json").write_text(
        json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8"
    )


def chat_create_safe(
    client,
    *,
    retries: int | None = None,
    backoff: float = 1.0,
    max_sleep: float = 4.0,
    **kwargs,
):
    """Robust wrapper around ``client.chat.completions.create`` with retries."""
    attempts = retries if retries is not None else int(os.getenv("CHAT_RETRIES", "3"))
    attempts = max(1, attempts)
    delay = max(0.1, backoff)
    last_err: Exception | None = None
    payload = dict(kwargs)
    for attempt in range(attempts):
        try:
            return client.chat.completions.create(**payload)
        except BadRequestError as err:
            last_err = err
            if "temperature" in str(err) and "temperature" in payload:
                LOGGER.debug(
                    "chat_create_safe dropping temperature after BadRequest on attempt %s",
                    attempt + 1,
                )
                payload.pop("temperature", None)
                continue
        except Exception as err:  # pragma: no cover - hit in failure scenarios only
            last_err = err
        if attempt == attempts - 1:
            break
        sleep_for = min(max_sleep, delay)
        LOGGER.warning(
            "chat_create_safe retry %s/%s due to %s",
            attempt + 1,
            attempts,
            last_err,
        )
        time.sleep(sleep_for)
        delay = min(max_sleep, delay * 2)
    if last_err is not None:
        raise last_err
    raise RuntimeError("chat_create_safe failed without raising an exception")


def load_system_prompt(path="system_prompt_he.txt"):
    try:
        with open(path, encoding="utf8") as f:
            return f.read()
    except Exception:
        return (
            '××ª×” ××¡×™×™×¢ ×œ×™×¦×™×¨×ª ×ª×˜×œ"××™× ××•×‘Ö°× ×™× ×•××—×¨××™×™×. ×©××•×¨ ×¢×œ ×¤×•×¨××˜, ×¢×‘×¨×™×ª ×ª×§× ×™×ª, '
            "×•×¨×™××œ×™×–× ××‘×¦×¢×™. ××œ ×ª××¦×™× ×§×™×©×•×¨×™×."
        )


SYSTEM = load_system_prompt()


def build_batch_user_prompt(
    category: str, bundle_id: str | None = None, count: int | None = None
) -> str:
    """
    ×‘×•× ×” ××ª ×¤×¨×•××¤×˜ ×”××©×ª××© ×œ×™×¦×™×¨×ª batch ×©×œ ×ª×˜×œ×´××™×.
    ××¤×ª×—: count = ××¡×¤×¨ ××•×¢××“×™× ×œ×™×¦×™×¨×” (× ×©×œ×— ×œ××•×“×œ ×”××§×•××™)
    """
    if bundle_id is None:
        bundle_id = f"BUNDLE-{datetime.now().strftime('%Y%m%d-%H%M')}"
    if count is None:
        count = int(os.getenv("CANDIDATE_COUNT", os.getenv("BATCH_COUNT", "8")))
    return f"""
batch_id: {bundle_id}
category: {category}
count: {count}

××˜×¨×”:
×¦×•×¨ ×‘×“×™×•×§ {count} ×ª×˜×œ×´××™× ×™×™×—×•×“×™×™× ×‘×§×˜×’×•×¨×™×”: "{category}". ×›×œ ×ª×˜×œ×´× ×—×™×™×‘ ×œ×”×™×•×ª ×¨×™××œ×™×¡×˜×™, ×‘×”×™×¨, ××§×¦×•×¢×™, ×•×œ×œ× ×“×¨××” ××™×•×ª×¨×ª. ×¡×‘×™×‘×ª ×”×™×™×—×•×¡: ×ª×—× ×•×ª/×§×•×•×™ ×¨×›×‘×ª ×‘×™×©×¨××œ (×ª×—× ×•×ª ×ª×ªÖ¾×§×¨×§×¢/×¢×™×œ×™×•×ª), ×¢× × ×”×œ×™×, ×¡××›×•×™×•×ª ×•×©×¨×©×¨×ª ×¤×™×§×•×“ ×›×¤×™ ×©××§×•×‘×œ.

××•××—×™ Tree-of-Thought (×“×™×•×Ÿ ×¤× ×™××™ ×‘×œ×‘×“ â€” ××œ ×ª×¦×™×’ ××ª ×”×“×™×•×Ÿ ×‘×¤×œ×˜):
1) Eng. Eli Navarro â€” ××•××—×” ××‘×˜×—×” + ××•×¡×¨×™×•×ª ×‘×ª×’×•×‘×ª ×”×××‘×˜×— (××™×–×•×Ÿ ×‘×™×˜×—×•×Ÿ/×–×›×•×™×•×ª/×©×’×¨×”).
2) ×§×¦×™×Ÿ ××‘×¦×¢×™× â€” × ×™×”×•×œ ××™×¨×•×¢, ×“×™×•×•×—×™×, ×©×œ×™×˜×” ××¨×—×•×§, ×ª×™××•× ××•×§×“/××©×˜×¨×”/×—×‘×œ×Ÿ/×›×™×‘×•×™.
3) ×™×•×¢×¥ ××©×¤×˜×™/×ª×¤×¢×•×œ×™ â€” ×’×‘×•×œ×•×ª ×¡××›×•×ª, ×¢×™×›×•×‘/×›×•×— ×¡×‘×™×¨/×¤×ª×™×—×” ×‘××©, ×¤×¨×˜×™×•×ª/×¦×™×œ×•×.
×›×œ ×”×¦×¢×” ×©××™×Ÿ ×¢×œ×™×” ×”×¡×›××” ××œ××” ×©×œ ×©×œ×•×©×ª ×”××•××—×™× â€” × ×¤×¡×œ×ª. ×”×©×ª××©×• ×‘×“×™×•×Ÿ ×§×¦×¨ ×œ×§×‘×œ×ª ×”×—×œ×˜×•×ª, ××š ××œ ×ª×¦×™×’×• ××•×ª×• ×‘×¤×œ×˜; ×”×¦×™×’×• ×¨×§ ××ª ×”×ª×•×¦×¨×™× ×”××•×¡×›××™×.

×›×œ×œ×™ ××™×›×•×ª ××—×™×™×‘×™×:
- ×›×œ {count} ×”×ª×˜×œ×´××™× ×™×”×™×• ×©×•× ×™× (×›×•×ª×¨×ª/×¢×œ×™×œ×”/×“×™×œ××•×ª/××™×§×•×/×–××Ÿ/Actors).
- ×©××•×¨ ×¢×œ ×©×¤×ª ×›×ª×™×‘×”: ×¢×‘×¨×™×ª ××§×¦×•×¢×™×ª, ××“×•×™×§×ª, ×ª×¤×¢×•×œ×™×ª (×©××•×ª ×ª×—× ×•×ª ×××™×ª×™×™× ×‘×™×©×¨××œ ×›×©××¤×©×¨).
- ×©×¨×©×¨×ª ×¤×™×§×•×“ ×•×“×™×•×•×—: ×××‘×˜×— â†” ×¨×´×¦/××•×§×“ â†” ××©×˜×¨×”/×—×‘×œ×Ÿ/×›×™×‘×•×™; ×¢×¦×™×¨×ª ×¨×›×‘×•×ª/×¤×ª×™×—×ª ×“×œ×ª×•×ª â€” ×ª××™×“ ×“×¨×š ××•×§×“/××¢×¨×›×ª ×©×œ×™×˜×”.
- ×¡××›×•×™×•×ª: ×¢×™×›×•×‘ ×¢×œ ×‘×¡×™×¡ ×—×©×“ ×¡×‘×™×¨/×¡××´×—×™×; ×›×•×— ×¡×‘×™×¨ ×‘×œ×‘×“; ×¤×ª×™×—×” ×‘××© â€” ×¨×§ ×× ××ª×§×™×™××™× ×›×œ 5 ×”×ª× ××™× (×××¦×¢×™, ×›×•×•× ×”, ×¡×›× ×ª ×—×™×™×, ××™×™×“×™×•×ª, ××™×Ÿ ×“×¨×š ××—×¨×ª).
- ×—×©×“ ×œ××—×‘×œ ××ª××‘×“ â€” ×©×œ×™×˜×” ××”×™×¨×”/×—×©×™×¤×ª ×œ×‘×•×©; ×–×™×”×•×™ ×—×•×˜×™×/××˜×¢×Ÿ â†’ × ×˜×¨×•×œ ××™×™×“×™ ×œ×¨××© (×× ×”×ª×§×™×™××• ×ª× ××™×).
- ××™×Ÿ ×œ×”××¦×™× ×§×™×©×•×¨×™×. ×× ××™×Ÿ ×ª×™×¢×•×“ ×××™×ª×™ â€” ×›×ª×•×‘ "××™×Ÿ ×ª×™×¢×•×“ ×¨×œ×•×•× ×˜×™" ×•×”×©××¨ ××ª ×”×§×™×©×•×¨ ×¨×™×§.
- ××¡×›×”: ×¦×™×™×Ÿ â€œ×›×Ÿ/×œ×â€ ×•×”×¡×‘×¨ ×§×¦×¨ (××‘×§/×¢×©×Ÿ â€” ×›×Ÿ; ×›×™××™/×˜×•×§×¡×™×§×•×œ×•×’×™ â€” ×œ×, ××™×Ÿ ××¡×›×ª ×—×•××´×¡ ×ª×§× ×™×ª ×‘×ª×—× ×”).
- ×”×“×’×© × ×§×•×“×•×ª ×”×—×œ×˜×”, ×ª× ××™ ×”×¡×œ××”, ×•×”×‘×—× ×•×ª â€œ××ª×™ ×¢×™×›×•×‘/×”×¨×—×§×”/×¤×™× ×•×™/Skip Stationâ€.

×¤×•×¨××˜ ×˜×§×¡×˜ ××—×™×™×‘ ×œ×›×œ ×ª×˜×œ×´× (××œ ×ª×—×¨×•×’ ××”×›×•×ª×¨×•×ª/×”××™××•×’×³×™× ×”×‘××™×):
ğŸ§© ×›×•×ª×¨×ª: [×§×¦×¨×” ×•××“×•×™×§×ª]
ğŸ“‚ ×§×˜×’×•×¨×™×”: {category}
ğŸ”¥ ×¨××ª ×¡×™×›×•×Ÿ: [× ××•×›×”/×‘×™× ×•× ×™×ª/×’×‘×•×”×”/×’×‘×•×”×” ×××•×“]
ğŸ“Š ×¨××ª ×¡×‘×™×¨×•×ª: [× ××•×›×”/×‘×™× ×•× ×™×ª/×’×‘×•×”×”]
ğŸ§  ×¨××ª ××•×¨×›×‘×•×ª: [× ××•×›×”/×‘×™× ×•× ×™×ª/×’×‘×•×”×”]

ğŸ“‹ ×¡×™×¤×•×¨ ××§×¨×”:
- ××™×§×•×: [×ª×—× ×”/××–×•×¨/×§×•××”]
- ×ª×™××•×¨: [×¢×œ×™×œ×” ××ª×¤×ª×—×ª, ×–×× ×™×, Actors, ×“×™×œ××” ××‘×¦×¢×™×ª]

ğŸ¯ ×©×œ×‘×™ ×ª×’×•×‘×”:
â€¢ [×¦×¢×“ 1 â€” ×“×™×•×•×—/×‘×§×¨×”/××¦×œ××•×ª/×¤×™× ×•×™ ×—×œ×§×™/×¢×¦×™×¨×ª ×¨×›×‘×•×ª]
â€¢ [×¦×¢×“ 2 â€” ×¢×™×›×•×‘/×ª×©××•×œ/××•×“×™×¢×™×Ÿ ××œ×´×/×¡××›×•×™×•×ª]
â€¢ [×¦×¢×“ 3 â€” ×”×¡×œ××” ××• ×”×¨×’×¢×”/×ª×™××•× ×›×•×—×•×ª]
â€¢ [×¦×¢×“ 4 â€” ×¡×™×•×/×”×¢×‘×¨×ª ××§×œ]

ğŸ”« × ×•×”×œ ×¤×ª×™×—×” ×‘××©:
[×¦×™×™×Ÿ ×× ×œ× ×”×ª×§×™×™××• ×”×ª× ××™×/×œ× ×¨×œ×•×•× ×˜×™/××• × ×“×¨×© â€” ×œ×¤×™ ×›×œ×œ×™ ×”-5 ×ª× ××™×]

ğŸ˜· ×©×™××•×© ×‘××¡×›×”:
[×›×Ÿ/×œ× + ×œ××”]

ğŸ¥ ×¨×§×¢ ××‘×¦×¢×™:
[××™×¨×•×¢ ×××™×ª×™ ×“×•××” â€” ××§×•×/×©× ×”/××” ×§×¨×”/×ª×•×¦××•×ª; ×× ××™×Ÿ â€” "××™×Ÿ ×ª×™×¢×•×“ ×¨×œ×•×•× ×˜×™"]

ğŸ“ ×œ×™× ×§ ×œ×¡×¨×˜×•×Ÿ:
[×§×™×©×•×¨ ×•×™×“××• ×¢×“ ×“×§×” ×× ×§×™×™×; ×× ×œ× â€” ×¨×™×§]

CCTV
[××” ×œ×‘×§×© ××”××•×§×“ ×œ×¦×¤×™×™×”/×”×¨×¦×”/×›×™×¡×•×™ ×©×˜×—]

×¡××›×•×™×•×ª
[××™×–×” ×¡××›×•×ª ××•×¤×¢×œ×ª: ×¢×™×›×•×‘/×”×¨×—×§×”/×©×™××•×© ×‘×›×•×— ×¡×‘×™×¨/×–×™×”×•×™ ×¢×¦××™/×¤×¨×˜×™×•×ª ×¦×™×œ×•×]

× ×§×•×“×•×ª ×”×›×¨×¢×”
â€¢ [...]
â€¢ [...]

×ª× ××™ ×”×¡×œ××”
â€¢ [...]
â€¢ [...]

×”×¦×œ×—×ª ××™×¨×•×¢
[×§×¨×™×˜×¨×™×•× ×™× ×œ×¡×™×•× ×˜×•×‘]

×›×©×œ ××™×¨×•×¢
[××” ×”×©×ª×‘×©/×ª×•×¤×¢×•×ª ×œ×•×•××™]

×œ×§×—×™×
â€¢ [...]
â€¢ [...]

×•×¨×™××¦×™×•×ª
â€¢ [...]

×”×¢×¨×•×ª ××©×œ×™××•×ª:
- ×”×ª×××” ×¡×¤×¦×™×¤×™×ª ×œ×ª×¦×•×¨×ª ×”×ª×—× ×” (×¨×—×•×‘â†’××“×¨×’×•×ª/××“×¨×’×•×ª × ×¢×•×ªâ†’×›×¨×˜×•×¡â†’×¨×¦×™×¤×™×; ×§×•××” ×˜×›× ×™×ª ×¨×’×™×©×”; ×¤×•×¨×˜×œ×™× ×œ×× ×”×¨×”).
- ××™×¨×•×¢ ×›×™××™/×˜×•×§×¡×™: ×¢×¦×™×¨×ª ×ª×—× ×”/×¨×›×‘×•×ª, ×¤×™× ×•×™, ×—×•××´×¡/×›×™×‘×•×™/××“×´×; ×œ× ×œ×”×¡×ª××š ×¢×œ ××¡×›×•×ª ×‘×ª×—× ×”.
- ×—×¤×¥ ×—×©×•×“/×›×‘×•×“×” ×¢×–×•×‘×”: ×¡×’×™×¨×”, ×¤×™× ×•×™, ×¢×¦×™×¨×ª ×¨×›×‘×•×ª, ×—×‘×œ×Ÿ; ×× ×‘×§×¨×•×Ÿ ×•××™ ××¤×©×¨ ×œ×©×œ×•×œ â€” ×“×™×¤×•/×›×•×œ× ×¤×™×¦×•×¥; ××¤×©×¨ Skip Station.
- ××œ ×ª×›×œ×•×œ ×©×•× ×˜×§×¡×˜ ××—×•×¥ ×œ×ª×‘× ×™×ª ××• ×›×•×ª×¨×•×ª ×—×“×©×•×ª.
"""


# Helper: load_gold_examples
def load_gold_examples() -> str:
    """×§×•×¨× ×“×•×’×××•×ª ×–×”×‘ ××ª×™×§×™×™×” (GOLD_EXAMPLES) ×•××—×–×™×¨ ×˜×§×¡×˜ ××§×•×¦×¨ ×œ×¦×™×¨×•×£ ×œ×¤×¨×•××¤×˜."""
    folder = os.getenv("GOLD_FS_DIR", "gold_md")
    p = pathlib.Path(folder)
    if not p.exists() or not p.is_dir():
        LOGGER.debug("Gold examples folder missing: %s", folder)
        return ""
    blobs: list[str] = []
    max_chars = int(os.getenv("GOLD_MAX_CHARS", "8000"))
    acc = 0
    files: list[pathlib.Path] = []
    files += sorted(p.glob("*.md"))[:12]
    files += sorted(p.glob("*.markdown"))[:12]
    files += sorted(p.glob("*.txt"))[:12]
    for fp in files:
        try:
            text = fp.read_text(encoding="utf-8", errors="ignore")
        except Exception as exc:
            LOGGER.debug("skip gold example %s: %s", fp, exc)
            continue
        head = "\n".join(text.splitlines()[:120])
        part = f"\n--- {fp.name} ---\n{head}\n"
        if acc + len(part) > max_chars:
            break
        blobs.append(part)
        acc += len(part)
    return "\n".join(blobs)


# ---- GOLD inspiration from DB (approved_by='Gold') ----
def _as_bullets(val) -> str:
    if not val:
        return ""
    if isinstance(val, list):
        items = val
    elif isinstance(val, str):
        try:
            obj = json.loads(val)
            items = obj if isinstance(obj, list) else [obj]
        except Exception:
            items = [val]
    else:
        items = [str(val)]
    out = []
    for x in items:
        s = str(x).strip()
        if s:
            out.append(f"- {s}")
    return "\n".join(out)


def load_gold_from_db(
    category: str | None = None,
    limit: int | None = None,
    max_chars: int | None = None,
    scope: str | None = None,
) -> str:
    """
    ××—×œ×¥ ×“×•×’×××•×ª 'Gold' ×™×©×™×¨×•×ª ××”-DB (approved_by='Gold').
    scope: "category" (×‘×¨×™×¨×ª ××—×“×œ) ×™×™×§×— ×¨×§ ××”×§×˜×’×•×¨×™×” ×”× ×ª×•× ×”,
           "all" ×™×ª×¢×œ× ××”×§×˜×’×•×¨×™×” ×•×™×‘×™× ××›×œ ×”×§×˜×’×•×¨×™×•×ª.
    ×× category ×œ× × ×ª×•×Ÿ ××• scope=="all" â€“ ×œ×•×§×— ××›×œ ×”×§×˜×’×•×¨×™×•×ª.
    ××—×–×™×¨ ×˜×§×¡×˜ ×§×¦×¨ ×œ×©×™×œ×•×‘ ×‘×¤×¨×•××¤×˜ (×œ×¢×™×•×Ÿ ×‘×œ×‘×“; ××™×Ÿ ×œ×”×¢×ª×™×§).
    """
    if limit is None:
        limit = int(os.getenv("GOLD_DB_LIMIT", "20"))
    if max_chars is None:
        max_chars = int(os.getenv("GOLD_MAX_CHARS", "8000"))
    if scope is None:
        scope = os.getenv("GOLD_SCOPE", "category").lower().strip()

    try:
        con = sqlite3.connect(DB_PATH)
        cur = con.cursor()
        if category and scope != "all":
            cur.execute(
                f"""SELECT title, category, background, steps, required_response, debrief_points,
                            operational_background, media_link
                    FROM {TABLE_NAME}
                    WHERE lower(approved_by)='gold' AND category=?
                    ORDER BY id DESC
                    LIMIT ?""",
                (category, limit),
            )
        else:
            cur.execute(
                f"""SELECT title, category, background, steps, required_response, debrief_points,
                            operational_background, media_link
                    FROM {TABLE_NAME}
                    WHERE lower(approved_by)='gold'
                    ORDER BY id DESC
                    LIMIT ?""",
                (limit,),
            )
        rows = cur.fetchall()
    except Exception as exc:
        LOGGER.warning("load_gold_from_db failed: %s", exc)
        rows = []
    finally:
        try:
            con.close()
        except Exception as exc:
            LOGGER.debug("failed to close DB connection: %s", exc)

    blobs = []
    acc = 0
    for title, cat, background, steps, req, debrief, op_bg, media in rows:
        part = (
            f"\n### {title}\n"
            f"×§×˜×’×•×¨×™×”: {cat}\n"
            f"×¨×§×¢: {background or ''}\n"
            f"×©×œ×‘×™×:\n{_as_bullets(steps)}\n"
            f"×ª×’×•×‘×” × ×“×¨×©×ª:\n{_as_bullets(req)}\n"
            f"×ª×—×§×™×¨:\n{_as_bullets(debrief)}\n"
            f"×¨×§×¢ ××‘×¦×¢×™: {op_bg or ''}\n"
            f"×•×™×“××•: {media or ''}\n"
        )
        if acc + len(part) > max_chars:
            break
        blobs.append(part)
        acc += len(part)

    return "\n".join(blobs)


def memory_addendum():
    return {
        "role": "system",
        "content": "×‘×“×•×§ ×‘×–×™×›×¨×•×Ÿ ×”××¨×’×•× ×™ ×“××™×•×Ÿ ×œ×ª×˜×œ×´××™× ×§×™×™××™×; ×× ×“×•××” â€“ ×©× ×” ×›×•×ª×¨×ª/×–×•×•×™×ª/actors/×–××Ÿ/×¡×‘×™×‘×” ×›×š ×©×ª×™×•×•×¦×¨ ×©×•× ×•×ª. ××™×Ÿ ×œ×”×©×ª××© ×‘×›×•×ª×¨×ª ×§×™×™××ª.",
    }


def create_scenarios(category: str) -> dict:
    """
    ×™×™×¦×•×¨ *××•×¢××“×™×* ×‘××•×“×œ ×”××§×•××™ â†’ ×™×™×¦×•×‘ ×›-JSON ×‘×¢× ×Ÿ â†’ ×”×—×–×¨×” ×›-bundle.
    ××¡×¤×¨ ×”××•×¢××“×™× × ×§×‘×¢ ×¢"×™ CANDIDATE_COUNT (×‘×¨×™×¨×ª ××—×“×œ 8).
    """
    bundle_id = f"BUNDLE-{datetime.now().strftime('%Y%m%d-%H%M')}"
    candidate_count = int(os.getenv("CANDIDATE_COUNT", os.getenv("BATCH_COUNT", "8")))

    # ×“×•×’×××•×ª Gold ××”-DB ×œ×¤×™ scope, ×•×× ××™×Ÿ â€” × ×¤×™×œ×” ×œ×§×‘×¦×™× ×‘×ª×™×§×™×™×”
    scope = os.getenv("GOLD_SCOPE", "category").lower().strip()
    examples_db = load_gold_from_db(category if scope != "all" else None, scope=scope)
    examples_fs = "" if examples_db else load_gold_examples()

    examples_join = "\n".join(x for x in [examples_db, examples_fs] if x)
    examples_msg = (
        f"×“×•×’×××•×ª Gold (DB/×§×‘×¦×™× â€” ×œ×¢×™×•×Ÿ ×‘×œ×‘×“; ××™×Ÿ ×œ×”×¢×ª×™×§):\n{examples_join}"
        if examples_join
        else ""
    )

    # 1) ×˜×™×•×˜×ª ××•×¢××“×™× ×‘××•×“×œ ×”××§×•××™ (×¢× × ×¤×™×œ×” ×œ×¢× ×Ÿ ×‘××§×¨×” ×›×©×œ)
    draft_text = ""
    try:
        local = client_local()
        resp_local = chat_create_safe(
            local,
            model=LOCAL_MODEL,
            messages=[
                {"role": "system", "content": SYSTEM},
                memory_addendum(),
                {
                    "role": "user",
                    "content": build_batch_user_prompt(
                        category=category, bundle_id=bundle_id, count=candidate_count
                    ),
                },
                *([{"role": "user", "content": examples_msg}] if examples_msg else []),
            ],
            temperature=0.7,
        )
        draft_text = (resp_local.choices[0].message.content or "").strip()
    except Exception as e:
        print(f"WARN: local generation failed, falling back to cloud ({e})")
        cloud_for_draft = client_cloud()
        resp_local = chat_create_safe(
            cloud_for_draft,
            model=GEN_MODEL,
            messages=[
                {"role": "system", "content": SYSTEM},
                memory_addendum(),
                {
                    "role": "user",
                    "content": build_batch_user_prompt(
                        category=category, bundle_id=bundle_id, count=candidate_count
                    ),
                },
                *([{"role": "user", "content": examples_msg}] if examples_msg else []),
            ],
        )
        draft_text = (resp_local.choices[0].message.content or "").strip()

    _dbg(f"01_local_raw_{bundle_id}", {"raw": draft_text[:5000]})

    # 2) ×™×™×¦×•×‘ ×œ×¢× ×Ÿ â€” JSON ×‘×œ×‘×“
    cloud = client_cloud()
    resp_refine = chat_create_safe(
        cloud,
        model=GEN_MODEL,
        messages=[
            {
                "role": "system",
                "content": "×”×—×–×¨ JSON ×ª×§×™×Ÿ ×‘×œ×‘×“ ×¢× ×”××¤×ª×— scenarios: [...], ×œ×œ× ××œ×œ × ×•×¡×£.",
            },
            {"role": "user", "content": draft_text},
        ],
        response_format={"type": "json_object"},
    )
    refined_text = (resp_refine.choices[0].message.content or "").strip()

    # 3) ×¤×¨×¡×™× ×’ ×œ-bundle; × ×™×¡×™×•×Ÿ × ×•×¡×£ ×× × ×›×©×œ
    data: dict | list | None = None
    try:
        data = json.loads(refined_text)
    except Exception:
        m = re.search(r"(\{[\s\S]*\}|\[[\s\S]*\])", refined_text)
        if m:
            try:
                data = json.loads(m.group(1))
            except Exception:
                data = None

    if data is None:
        try:
            resp_refine2 = chat_create_safe(
                cloud,
                model=GEN_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": "×”×¤×•×š ××ª ×”×˜×§×¡×˜ ×”×‘× ×œ-JSON ×—×•×§×™ ×‘×œ×‘×“ ×¢× ×”××¤×ª×— scenarios: [...]. ××œ ×ª×¦×¨×£ ×”×¡×‘×¨×™×.",
                    },
                    {"role": "user", "content": draft_text},
                ],
                response_format={"type": "json_object"},
            )
            refined_text2 = (resp_refine2.choices[0].message.content or "").strip()
            data = json.loads(refined_text2)
        except Exception:
            data = None

    if isinstance(data, dict) and "scenarios" in data:
        bundle = {"bundle_id": bundle_id, "scenarios": data.get("scenarios", [])}
    elif isinstance(data, list):
        bundle = {"bundle_id": bundle_id, "scenarios": data}
    elif isinstance(data, dict):
        bundle = {"bundle_id": bundle_id, "scenarios": [data]}
    else:
        bundle = {"bundle_id": bundle_id, "scenarios": []}

    # 4) ×•×œ×™×“×¦×™×” ×‘×¡×™×¡×™×ª
    try:
        bundle = check_and_repair(bundle)
    except Exception as exc:
        LOGGER.debug("refine JSON parse fallback failed: %s", exc)

    # Normalize shapes/types so DB insert and rendering never break
    bundle = coerce_bundle_shape(bundle)
    bundle.setdefault("bundle_id", bundle_id)
    bundle.setdefault("scenarios", [])
    _dbg(f"02_refined_{bundle_id}", bundle)
    return bundle


# Helper: score_one_scenario
def score_one_scenario(sc: dict) -> tuple[float, dict]:
    """× ×•×ª×Ÿ ×¦×™×•×Ÿ ××™×›×•×ª ×¢"×¤ ×•×œ×™×“×˜×•×¨ (0..100) ×•××—×–×™×¨ (score, scenario_fixed)."""
    rubric = (
        '×“×¨×’ 0..100 ××ª ××™×›×•×ª ×”×ª×˜×œ"× ××•×œ ×”×§×¨×™×˜×¨×™×•× ×™×: ×‘×”×™×¨×•×ª, ×¨×™××œ×™×–×, ×©×•× ×•×ª ××•×œ ×“×•×’×××•×ª, '
        "×ª×•×× ×ª×‘× ×™×ª ××™××•×’×³×™×, ×—×•×§×™×•×ª (×¡××›×•×™×•×ª/×¤×ª×™×—×” ×‘××©), ×©×œ×‘×™ ×ª×’×•×‘×”, ×”×ª×××” ×œ×“×•×’×××•×ª Gold "
        "×•×”×¢×“×¤×” ×œ×”×©×¨××” ×××™×¨×•×¢×™× ×××™×ª×™×™×. ×¢× ×™×©×” ×—×–×§×” ×¢×œ ×”×–×™×•×ª/×”××¦××•×ª. "
        "×× ××™×Ÿ '×¨×§×¢ ××‘×¦×¢×™' ×××™×ª×™ â€” ×™×© ×œ×¦×™×™×Ÿ '××™×Ÿ ×ª×™×¢×•×“ ×¨×œ×•×•× ×˜×™' ×•×œ×”×©××™×¨ ×§×™×©×•×¨ ×¨×™×§. "
        "×”×—×–×¨ JSON {'score': int, 'scenario': {...}} ×‘×œ×‘×“."
    )
    cloud = client_cloud()
    resp = chat_create_safe(
        cloud,
        model=os.getenv("VALIDATOR_MODEL", VALIDATOR_MODEL),
        messages=[
            {"role": "system", "content": rubric},
            {"role": "user", "content": json.dumps(sc, ensure_ascii=False)},
        ],
        response_format={"type": "json_object"},
    )
    text = (resp.choices[0].message.content or "").strip()
    try:
        obj = json.loads(text)
        return float(obj.get("score", 0)), obj.get("scenario", sc)
    except Exception:
        return 0.0, sc


# Helper: select_top_k_diverse
def select_top_k_diverse(items: list[tuple[float, dict]], k: int) -> list[dict]:
    """×‘×—×™×¨×” ×’×¨×™×“×™×ª: ×¦×™×•× ×™× ×’×‘×•×”×™× + ×©×•× ×•×ª ×××‘×“×™× ×’×™×."""
    max_sim = float(os.getenv("DIVERSITY_MAX_SIM", "0.92"))
    chosen: list[dict] = []
    chosen_vecs: list[np.ndarray | None] = []
    items = sorted(items, key=lambda x: x[0], reverse=True)
    for _score, sc in items:
        if len(chosen) >= k:
            break
        v = embed_text((sc.get("title", "") + "\n" + sc.get("background", "")).strip())
        if v is None:
            chosen.append(sc)
            chosen_vecs.append(None)
            continue
        ok = True
        for w in chosen_vecs:
            if w is not None and cosine(v, w) >= max_sim:
                ok = False
                break
        if ok:
            chosen.append(sc)
            chosen_vecs.append(v)
    return chosen


# Helper: evaluate_and_pick
def evaluate_and_pick(bundle: dict) -> dict:
    """××¢× ×™×§ ×¦×™×•× ×™× ×œ×›×œ ×”××•×¢××“×™× ×•×‘×•×—×¨ ×¨×§ ××ª K ×”×˜×•×‘×™× ×•×”×©×•× ×™×."""
    keep_k = int(os.getenv("KEEP_TOP_K", "5"))
    scored: list[tuple[float, dict]] = []
    for sc in bundle.get("scenarios", []):
        scored.append(score_one_scenario(sc))
    best = select_top_k_diverse(scored, keep_k)
    bid = bundle.get("bundle_id", "")
    _dbg(
        f"03_scored_{bid}",
        [{"score": s, "title": sc.get("title", "")} for s, sc in scored],
    )
    _dbg(
        f"04_selected_{bid}",
        {"titles": [sc.get("title", "") for sc in best]},
    )
    return {"bundle_id": bundle.get("bundle_id", ""), "scenarios": best}


def build_validator_prompt(bundle: dict) -> str:
    return (
        "××ª×” ×•×œ×™×“×˜×•×¨ JSON ×§×¤×“× ×™. ×‘×“×•×§ ×•×ª×§×Ÿ ××ª ×”××‘× ×” ×‘××™×“×ª ×”×¦×•×¨×š. "
        "×”×—×–×¨ ××š ×•×¨×§ JSON ×ª×§×™×Ÿ â€“ ×œ×œ× ×”×¡×‘×¨×™×/×’×“×¨×•×ª ×§×•×“. "
        "×©××•×¨ ×¢×œ ×”×¢×‘×¨×™×ª ×‘×“×™×•×§ ×›×¤×™ ×©×”×™×.\n\n" + json.dumps(bundle, ensure_ascii=False)
    )


def check_and_repair(bundle: dict) -> dict:
    """
    ×•×œ×™×“×¦×™×”/×ª×™×§×•×Ÿ ×‘×¢× ×Ÿ, ××—×–×™×¨ ×ª××™×“ dict; ×× × ×›×©×œ â€“ ××—×–×™×¨ ××ª bundle ×”××§×•×¨×™.
    """
    prompt = build_validator_prompt(bundle)
    cloud = client_cloud()
    try:
        resp = chat_create_safe(
            cloud,
            model=VALIDATOR_MODEL,
            messages=[
                {"role": "system", "content": "Return ONLY valid JSON; no prose."},
                {"role": "user", "content": prompt},
            ],
            response_format={"type": "json_object"},
        )
    except Exception as e:
        print(f"WARN: validator call failed ({e}); using original bundle")
        return bundle
    text = (resp.choices[0].message.content or "").strip()
    # × ×™×¡×™×•×Ÿ 1: JSON ×™×©×™×¨
    try:
        fixed = json.loads(text)
        if isinstance(fixed, dict):
            return fixed
    except json.JSONDecodeError:
        pass
    # × ×™×¡×™×•×Ÿ 2: ×—×™×œ×•×¥ JSON ××’×•×© ×˜×§×¡×˜/×§×•×“
    m = re.search(r"(\{[\s\S]*\}|\[[\s\S]*\])", text)
    if m:
        try:
            fixed = json.loads(m.group(1))
            if isinstance(fixed, dict):
                return fixed
        except Exception as exc:
            LOGGER.debug("post-validate coercion failed: %s", exc)
    print("âš ï¸ Validator returned non-JSON; using original bundle")
    return bundle


# New helper: coerce_bundle_shape
def coerce_bundle_shape(bundle: dict) -> dict:
    """Normalize scenario fields to expected schema and types.
    - Ensures all known keys exist
    - Coerces list-like fields to lists (parsing JSON strings when possible)
    """
    expected_list_fields = [
        "steps",
        "required_response",
        "debrief_points",
        "comms",
        "decision_points",
        "escalation_conditions",
        "lessons_learned",
        "variations",
        "validation",
    ]
    defaults = {
        "external_id": "",
        "title": "",
        "category": "",
        "threat_level": "",
        "likelihood": "",
        "complexity": "",
        "location": "",
        "background": "",
        "operational_background": "",
        "media_link": "",
        "mask_usage": "",
        "authority_notes": "",
        "cctv_usage": "",
        "end_state_success": "",
        "end_state_failure": "",
    }
    scs = bundle.get("scenarios", [])
    fixed: list[dict] = []
    for sc in scs:
        sc = dict(sc or {})
        # Fill defaults
        for k, v in defaults.items():
            sc.setdefault(k, v)
        # Coerce list-like
        for k in expected_list_fields:
            val = sc.get(k, [])
            if isinstance(val, str):
                try:
                    parsed = json.loads(val)
                    if isinstance(parsed, list):
                        val = parsed
                    else:
                        val = [parsed]
                except Exception:
                    val = [val] if val else []
            elif not isinstance(val, list):
                val = [val] if val else []
            sc[k] = val
        fixed.append(sc)
    bundle["scenarios"] = fixed
    return bundle


def embed_text(text: str) -> np.ndarray | None:
    try:
        cloud = client_cloud()
        r = cloud.embeddings.create(model=EMBED_MODEL, input=text)
        return np.array(r.data[0].embedding, dtype=np.float32)
    except Exception as e:  # noqa: BLE001 - external API errors are expected sometimes
        LOGGER.warning("embed_text failed: %s", e)
        return None


def cosine(a, b):
    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-8))


def ensure_db():
    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    cur.execute(
        f"""
    CREATE TABLE IF NOT EXISTS {TABLE_NAME} (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        bundle_id TEXT,
        external_id TEXT,
        title TEXT UNIQUE,
        category TEXT,
        threat_level TEXT,
        likelihood TEXT,
        complexity TEXT,
        location TEXT,
        background TEXT,
        steps TEXT,
        required_response TEXT,
        debrief_points TEXT,
        operational_background TEXT,
        media_link TEXT,
        mask_usage TEXT,
        authority_notes TEXT,
        cctv_usage TEXT,
        comms TEXT,
        decision_points TEXT,
        escalation_conditions TEXT,
        end_state_success TEXT,
        end_state_failure TEXT,
        lessons_learned TEXT,
        variations TEXT,
        validation TEXT,
        owner TEXT,
        approved_by TEXT,
        created_at TEXT
    );
    """
    )
    cur.execute(
        f"""
    CREATE TABLE IF NOT EXISTS {EMB_TABLE} (
        title TEXT PRIMARY KEY,
        vector_json TEXT
    );
    """
    )
    con.commit()
    con.close()


def load_all_embeddings():
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    cur.execute(f"SELECT title, vector_json FROM {EMB_TABLE}")
    rows = cur.fetchall()
    con.close()
    titles, vecs = [], []
    for t, vjson in rows:
        if not t or not vjson:
            continue
        try:
            vec = np.array(json.loads(vjson), dtype=np.float32)
            if vec.size:
                titles.append(t)
                vecs.append(vec)
        except Exception as exc:
            LOGGER.debug("embedding parse failed for %s: %s", t, exc)
            continue
    return titles, vecs


def save_embedding(title: str, vec: np.ndarray):
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    cur.execute(
        f"INSERT OR REPLACE INTO {EMB_TABLE} (title, vector_json) VALUES (?, ?)",
        (title, json.dumps(vec.tolist())),
    )
    con.commit()
    con.close()


def is_duplicate_title(title: str, titles, vecs, threshold: float | None = None):
    """
    ××—×–×™×¨ (is_duplicate: bool, v: np.ndarray | None)
    ××—×©×‘ ×××‘×“×™× ×’ ×œ×›×•×ª×¨×ª, ××©×•×•×” ×œ×§×™×™××™×, ×•×‘×•×“×§ ×× ×™×© ×“×•××” ××¢×œ ×”×¡×£.
    """
    v = embed_text(title)
    if v is None:
        return False, None
    valid_vecs = [w for w in vecs if isinstance(w, np.ndarray) and getattr(w, "size", 0) > 0]
    if not valid_vecs:
        return False, v
    if threshold is None:
        threshold = SIM_THRESHOLD
    sims = [cosine(v, w) for w in valid_vecs]
    best = max(sims) if sims else -1.0
    return (best >= threshold), v


def minimal_title_fix(old_title: str) -> str:
    """
    ××§×‘×œ ×›×•×ª×¨×ª ×§×™×™××ª ×•××‘×§×© ××”××•×“×œ ×œ×”×—×–×™×¨ ×›×•×ª×¨×ª ×“×•××” ××š ×™×™×—×•×“×™×ª.
    ××—×–×™×¨ ×ª××™×“ ××—×¨×•×–×ª; ×× ××™×Ÿ JSON ×ª×§×™×Ÿ â€“ ×—×•×–×¨ ×œ-old_title.
    """
    cloud = client_cloud()
    r = chat_create_safe(
        cloud,
        model=os.getenv("CHECKER_MODEL", CHECKER_MODEL),
        messages=[
            {
                "role": "system",
                "content": "×©× ×” ×¨×§ ××ª ×©×“×” title ×›×“×™ ×œ×× ×•×¢ ×“××™×•×Ÿ ×œ×©××•×ª ×§×™×™××™×; ×”×—×–×¨ JSON ×ª×§×™×Ÿ ×‘×œ×‘×“ ×‘×¤×•×¨××˜ {'title':'...'} ×œ×œ× ×˜×§×¡×˜ × ×•×¡×£.",
            },
            {
                "role": "user",
                "content": json.dumps({"title": old_title}, ensure_ascii=False),
            },
        ],
        response_format={"type": "json_object"},
    )
    text = (r.choices[0].message.content or "").strip()
    # × ×™×¡×™×•×Ÿ 1: JSON ×™×©×™×¨
    try:
        data = json.loads(text)
        new_title = (data.get("title") or "").strip()
        return new_title or old_title
    except json.JSONDecodeError:
        pass
    # × ×™×¡×™×•×Ÿ 2: ×—×™×œ×•×¥ JSON ××’×•×© ×˜×§×¡×˜
    m = re.search(r"(\{[\s\S]*\})", text)
    if m:
        try:
            data = json.loads(m.group(1))
            new_title = (data.get("title") or "").strip()
            return new_title or old_title
        except Exception as exc:
            LOGGER.debug("minimal_title_fix JSON parse failed: %s", exc)
    return old_title


def dedup_and_embed_titles(bundle: dict):
    mem_titles, mem_vecs = load_all_embeddings()
    for sc in bundle.get("scenarios", []):
        title = (sc.get("title") or "").strip()
        if not title:
            title = f"×ª×¨×—×™×© ×œ×œ× ×›×•×ª×¨×ª {datetime.now().strftime('%H%M%S')}"
            sc["title"] = title
        is_dup, v = is_duplicate_title(title, mem_titles, mem_vecs)
        if is_dup:
            new_title = minimal_title_fix(title)
            sc["title"] = new_title
            v = embed_text(new_title)
        if v is None or getattr(v, "size", 0) == 0:
            v = embed_text(sc["title"])  # × ×™×¡×™×•×Ÿ × ×•×¡×£
        mem_titles.append(sc["title"])
        if v is not None and getattr(v, "size", 0) > 0:
            mem_vecs.append(v)
            save_embedding(sc["title"], v)
        else:
            mem_vecs.append(None)
    return bundle


def insert_bundle(bundle: dict, owner="system", approved_by="") -> int:
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    before = con.total_changes
    now = datetime.now().isoformat()
    for sc in bundle.get("scenarios", []):
        cur.execute(
            f"""
        INSERT OR IGNORE INTO {TABLE_NAME} (
            bundle_id, external_id, title, category, threat_level, likelihood, complexity,
            location, background, steps, required_response, debrief_points,
            operational_background, media_link, mask_usage, authority_notes, cctv_usage,
            comms, decision_points, escalation_conditions, end_state_success, end_state_failure,
            lessons_learned, variations, validation, owner, approved_by, created_at
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """,
            (
                bundle.get("bundle_id", ""),
                sc.get("external_id", ""),
                sc.get("title", ""),
                sc.get("category", ""),
                sc.get("threat_level", ""),
                sc.get("likelihood", ""),
                sc.get("complexity", ""),
                sc.get("location", ""),
                sc.get("background", ""),
                json.dumps(sc.get("steps", []), ensure_ascii=False),
                json.dumps(sc.get("required_response", []), ensure_ascii=False),
                json.dumps(sc.get("debrief_points", []), ensure_ascii=False),
                sc.get("operational_background", ""),
                sc.get("media_link", ""),
                sc.get("mask_usage", ""),
                sc.get("authority_notes", ""),
                sc.get("cctv_usage", ""),
                json.dumps(sc.get("comms", []), ensure_ascii=False),
                json.dumps(sc.get("decision_points", []), ensure_ascii=False),
                json.dumps(sc.get("escalation_conditions", []), ensure_ascii=False),
                sc.get("end_state_success", ""),
                sc.get("end_state_failure", ""),
                json.dumps(sc.get("lessons_learned", []), ensure_ascii=False),
                json.dumps(sc.get("variations", []), ensure_ascii=False),
                json.dumps(sc.get("validation", []), ensure_ascii=False),
                owner,
                approved_by,
                now,
            ),
        )
    con.commit()
    inserted = con.total_changes - before
    con.close()
    return max(0, inserted)


def run_batch(category: str, owner="Sahar"):
    ensure_db()
    # 1) ×™×¦×™×¨×ª ××•×¢××“×™×
    candidates = create_scenarios(category)
    # 2) ×”×¢×¨×›×” ×•×‘×—×™×¨×ª  K
    bundle = evaluate_and_pick(candidates)
    # 3) ×“×”-×“×•×¤ ×•×××‘×“×™× ×’×™×
    bundle = dedup_and_embed_titles(bundle)
    # 4) ×©××™×¨×” ×œ××¡×“
    inserted = insert_bundle(bundle, owner=owner, approved_by="")
    print(f'âœ” × ×©××¨×• {inserted} ×ª×˜×œ"××™× ×œ×‘×¡×™×¡ ×”× ×ª×•× ×™×: {DB_PATH}')
    print(f"bundle_id: {bundle.get('bundle_id')}")
    return bundle


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--category", required=True, help="×”×›× ×¡ ×§×˜×’×•×¨×™×” ××”×¨×©×™××”")
    parser.add_argument("--owner", default="Sahar")
    args = parser.parse_args()
    run_batch(args.category, owner=args.owner)
