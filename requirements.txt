# Trinity Streamlit System - Core Dependencies

# UI Framework
streamlit>=1.32.0
pandas>=2.2.0
textual>=0.47.0  # TUI framework for ops dashboard

# AI Model Clients
openai>=1.40.0              # Local Qwen server (OpenAI-compatible)
anthropic>=0.18.0           # Claude Writer
google-generativeai>=0.4.0  # Gemini Judge

# Utilities
python-dotenv>=1.0.0        # Environment variables
watchdog>=4.0.0             # File system monitoring
tenacity>=8.2.0             # Professional retry logic with exponential backoff
pydantic>=2.0.0             # Strict data validation for LLM outputs

# Database ORM
SQLAlchemy>=2.0.0           # Modern ORM with type hints

# Local LLM (llama-cpp-python)
# NOTE: For Apple Silicon (M1/M2/M3/M4) with Metal GPU support,
# install manually with:
#
#   CMAKE_ARGS="-DGGML_METAL=on" pip install --force-reinstall --no-cache-dir llama-cpp-python
#
# This enables Metal acceleration for significant performance gains.
# The standard pip install does NOT include Metal support.
#
# Uncomment below for CPU-only installations:
# llama-cpp-python>=0.2.0
