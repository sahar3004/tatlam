"""
tatlam/graph/nodes/archivist.py - The Archivist Node

The Archivist handles the final step of the workflow:
- Saves approved scenarios to the database
- Stores embeddings for future deduplication
- Logs final metrics and summary

Key Features:
- Uses existing insert_scenario from repo.py
- Saves embeddings to ScenarioEmbedding table
- Handles partial failures gracefully
"""
from __future__ import annotations

import json
import logging
from typing import Any

import numpy as np

from tatlam.graph.state import SwarmState, ScenarioCandidate, ScenarioStatus, WorkflowPhase
from tatlam.infra.repo import insert_scenario
from tatlam.settings import get_settings

logger = logging.getLogger(__name__)


def _save_embedding(title: str, embedding: list[float]) -> bool:
    """Save an embedding to the database."""
    from tatlam.infra.db import get_session
    from tatlam.infra.models import ScenarioEmbedding

    try:
        with get_session() as session:
            # Check if exists
            existing = session.get(ScenarioEmbedding, title)
            if existing:
                existing.vector_json = json.dumps(embedding)
            else:
                emb = ScenarioEmbedding(
                    title=title,
                    vector_json=json.dumps(embedding)
                )
                session.add(emb)
            session.commit()
        return True
    except Exception as e:
        logger.warning("Failed to save embedding for '%s': %s", title, e)
        return False


def archivist_node(state: SwarmState) -> SwarmState:
    """
    Archivist Node: Save approved scenarios to the database.

    This node:
    1. Collects all approved scenarios
    2. Saves each to the database
    3. Stores embeddings for deduplication
    4. Marks scenarios as ARCHIVED
    5. Finalizes metrics

    Args:
        state: Current SwarmState

    Returns:
        Updated SwarmState with archived scenarios
    """
    state.log_phase_change(WorkflowPhase.ARCHIVING)

    # Get approved scenarios
    approved = state.approved_scenarios

    if not approved:
        logger.warning("Archivist: No approved scenarios to archive")
        state.log_phase_change(WorkflowPhase.COMPLETE)
        state.metrics.finalize()
        return state

    logger.info("Archivist archiving %d scenarios", len(approved))

    settings = get_settings()
    inserted_count = 0
    failed_count = 0

    for candidate in approved:
        # Prepare scenario data
        scenario_data = dict(candidate.data)

        # Remove internal fields
        scenario_data.pop("_embedding", None)
        scenario_data.pop("_raw_text", None)
        scenario_data.pop("_model", None)
        scenario_data.pop("_is_raw_draft", None)

        # Ensure bundle_id
        scenario_data["bundle_id"] = state.bundle_id

        try:
            # Insert scenario
            scenario_id = insert_scenario(
                scenario_data,
                owner="swarm",  # Mark as generated by swarm
                pending=False  # Auto-approve since it passed Judge
            )

            # Save embedding if available
            embedding = candidate.data.get("_embedding")
            if embedding:
                _save_embedding(candidate.title, embedding)

            # Mark as archived
            candidate.status = ScenarioStatus.ARCHIVED

            inserted_count += 1
            logger.debug("Archived: %s (id=%d)", candidate.title, scenario_id)

        except ValueError as e:
            # Likely duplicate title
            failed_count += 1
            logger.warning("Failed to archive '%s': %s", candidate.title, e)
        except Exception as e:
            failed_count += 1
            logger.error("Unexpected error archiving '%s': %s", candidate.title, e)
            state.add_error(f"Archive failed for '{candidate.title}': {e}")

    # Finalize
    state.log_phase_change(WorkflowPhase.COMPLETE)
    state.metrics.finalize()

    logger.info("=" * 50)
    logger.info("Mission Complete!")
    logger.info("=" * 50)
    logger.info("Bundle ID: %s", state.bundle_id)
    logger.info("Category: %s", state.category)
    logger.info("Archived: %d scenarios", inserted_count)
    logger.info("Failed: %d scenarios", failed_count)
    logger.info("Total Generated: %d", state.metrics.total_generated)
    logger.info("Total Approved: %d", state.metrics.total_approved)
    logger.info("Total Rejected: %d", state.metrics.total_rejected)
    logger.info("Average Score: %.1f", state.metrics.average_score)
    logger.info("Iterations: %d", state.iteration)
    logger.info("Errors: %d", len(state.errors))
    logger.info("=" * 50)

    return state


__all__ = ["archivist_node"]
